{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn import cluster\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib as g\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random\n",
    "import scipy\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_pickle('cleaned_movie_set.pkl')\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acquiring Genre Correlations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find genre correlations to see which genre categories are the most highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = movie\n",
    "c = df.corr().abs()\n",
    "s = c.unstack()\n",
    "so = s.sort_values(ascending=False, kind=\"quicksort\")\n",
    "genre_corr = so[28::2]\n",
    "genre_corr[0:28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acquiring Cumulative Sums and Label Counts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find how much of each the dataset each genre is a part of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [] #getting the counts per genre\n",
    "df = movie\n",
    "genres = df.columns[2::]\n",
    "for i in genres:\n",
    "    counts.append(df[i].value_counts().to_dict())\n",
    "#creating counts table\n",
    "counts_df = pd.DataFrame.from_dict(counts)\n",
    "counts_df[2] = genres\n",
    "counts_table = counts_df.drop([0], axis=1)\n",
    "counts_table = counts_table.rename(columns = {1:'counts', 2:'genre'})\n",
    "\n",
    "# Use sort instead of sort_values if error\n",
    "# counts_sort = counts_table.sort('counts', ascending=False)\n",
    "counts_sort = counts_table.sort_values('counts', ascending=False)\n",
    "\n",
    "#creating column of cumulative sums\n",
    "sumcol = counts_sort['counts'].sum()\n",
    "cumsum = counts_sort['counts']/sumcol\n",
    "counts_sort['cumsum'] = cumsum\n",
    "counts_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that the cumulative sum for Drama is much higher than other genres, and that there are few instance in other genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Displaying Correlation Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to graph a heatmap to visualize the correlation matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = movie\n",
    "genres = df.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genres = df.drop(df.columns[0],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sb.palplot(sb.color_palette(\"hls\", 7))\n",
    "R = np.corrcoef(df_genres,rowvar=False)\n",
    "genre_heatmap = sb.heatmap(R,cmap=\"Blues\",xticklabels=True, yticklabels=True)\n",
    "genre_heatmap.set_xticklabels(genres, rotation=90)\n",
    "genre_heatmap.set_yticklabels(genres)\n",
    "plt.show(genre_heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, there are not many categories that are too highly correlated, so we cannot group any categories together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Irrelevant Label Genres**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed the genres that make up less than 4% of the dataset as there is not enough data to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garb = counts_sort['genre'].where(counts_sort['cumsum']<.04).tolist()\n",
    "garb = garb[9:28]\n",
    "garb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df #clean dataset without garbage labels\n",
    "clean_df = clean_df.drop(garb, axis=1) #removing the unwanted genres from our dataset\n",
    "#clean_df = clean_df.drop(clean_df.columns[0], axis=1)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New Correlations after Removing Excess Labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to check the correlation between the genres again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Correlations after removing excess labels\n",
    "c = clean_df.corr().abs()\n",
    "s = c.unstack()\n",
    "so = s.sort_values(ascending=False, kind=\"quicksort\")\n",
    "genre_corr = so[9::2]\n",
    "genre_corr[1:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping Non-Contextual Genres**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Drama is often correlated with others, we decided to consider Drama a 'secondary' genre, not primary. Thus, it is not meaningful to include it in our dataset. \n",
    "Documentary and Adventure also offer little meaning since Documentary is related to Drama (according to correlation) and Adventure is essentially the same as Action. After removing these, we wanted to check the cumulative sums again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixgenres = clean_df.drop(['Adventure', 'Documentary', 'Mystery','Drama'], axis=1)\n",
    "sixgenres['sample']=0\n",
    "sixgenres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking Cumulative Sums after Removing Non-contextual Genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = sixgenres.columns[1:].tolist()\n",
    "counts = []\n",
    "for i in genres:\n",
    "    counts.append(sixgenres[i].value_counts().to_dict())\n",
    "counts_df = pd.DataFrame.from_dict(counts)\n",
    "counts_df[2] = genres\n",
    "counts_table = counts_df.drop([0], axis=1)\n",
    "counts_table = counts_table.rename(columns = {1:'counts', 2:'genre'})\n",
    "# Use sort instead of sort_values if error\n",
    "# counts_sort = counts_table.sort('counts', ascending=False)\n",
    "counts_sort = counts_table.sort_values('counts', ascending=False)\n",
    "\n",
    "sumcol = counts_sort['counts'].sum()\n",
    "cumsum = counts_sort['counts']/sumcol\n",
    "counts_sort['cumsum'] = cumsum\n",
    "counts_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, Comedy is 32% of all of our dataset. But since Comedy holds different features and properties than Drama, we decided to keep it and downsample Comedy instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downsampling Comedy to Balance Label Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['Action','Comedy','Crime','Horror','Romance','Thriller']\n",
    "sixgenres['Empty'] = sixgenres[col_list].sum(axis = 1)\n",
    "df = sixgenres[sixgenres.Empty != 0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy = df[df['Comedy'] == 1]\n",
    "np.random.seed = 1\n",
    "b = np.random.choice(comedy.Title,size = 4000, replace = False)\n",
    "df2 = comedy[comedy['Title'].isin(b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df[(df['Title'].isin(df2.Title) & df['Comedy'] == 1) | (df['Comedy'] == 0)]\n",
    "df4 = df3.drop(df3.columns[-2:],axis= 1)\n",
    "df4.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double-Checking Class Balance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = df4.columns[1:].tolist()\n",
    "counts = []\n",
    "for i in genres:\n",
    "    counts.append(df4[i].value_counts().to_dict())\n",
    "counts_df = pd.DataFrame.from_dict(counts)\n",
    "\n",
    "counts_df[2] = genres\n",
    "counts_table = counts_df.drop([0], axis=1)\n",
    "counts_table = counts_table.rename(columns = {1:'counts', 2:'genre'})\n",
    "\n",
    "# Use sort instead of sort_values if error:\n",
    "# counts_sort = counts_table.sort('counts', ascending=False)\n",
    "counts_sort = counts_table.sort_values('counts', ascending=False)\n",
    "\n",
    "#counts_sort\n",
    "sumcol = counts_sort['counts'].sum()\n",
    "cumsum = counts_sort['counts']/sumcol\n",
    "counts_sort['cumsum'] = cumsum\n",
    "counts_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsampling gave us this new dataset, which is much more balanced and efficient for our neurel nets and models (thinning our data this way greatly increased the speed of which the training set processed. We finished processing the data to have 6 classes, which will help model accuracy and speed. The resulting dataset has a little over 17 thousand values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pickling the new dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_pickle(\"Top6.pkl\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
